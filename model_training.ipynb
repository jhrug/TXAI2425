{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cfc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import Input, Model, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import prepare_dataframe, df_to_np_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0e1505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maduj\\anaconda3\\envs\\texai\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1f4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f6a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET_DIR = \"datasets/utkface/\"\n",
    "DATASET_DIR = \"UTKFace/\"\n",
    "IMG_DIM = 200\n",
    "INPUT_SHAPE = (IMG_DIM, IMG_DIM, 3)\n",
    "\n",
    "FIXED_KERNEL_SIZE = (3, 3)\n",
    "MIN_DENSE_UNITS = 16\n",
    "NUM_AGE_CLASSES = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdae1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f77fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Age_Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UTKFace/100_0_0_20170112213500903.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UTKFace/100_0_0_20170112215240346.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UTKFace/100_1_0_20170110183726390.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UTKFace/100_1_0_20170112213001988.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UTKFace/100_1_0_20170112213303693.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23700</th>\n",
       "      <td>UTKFace/9_1_3_20161220222856346.jpg.chip.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23701</th>\n",
       "      <td>UTKFace/9_1_3_20170104222949455.jpg.chip.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>UTKFace/9_1_4_20170103200637399.jpg.chip.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>UTKFace/9_1_4_20170103200814791.jpg.chip.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>UTKFace/9_1_4_20170103213057382.jpg.chip.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23705 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Image_Path  Age  Gender  Ethnicity  \\\n",
       "0      UTKFace/100_0_0_20170112213500903.jpg.chip.jpg  100       0          0   \n",
       "1      UTKFace/100_0_0_20170112215240346.jpg.chip.jpg  100       0          0   \n",
       "2      UTKFace/100_1_0_20170110183726390.jpg.chip.jpg  100       1          0   \n",
       "3      UTKFace/100_1_0_20170112213001988.jpg.chip.jpg  100       1          0   \n",
       "4      UTKFace/100_1_0_20170112213303693.jpg.chip.jpg  100       1          0   \n",
       "...                                               ...  ...     ...        ...   \n",
       "23700    UTKFace/9_1_3_20161220222856346.jpg.chip.jpg    9       1          3   \n",
       "23701    UTKFace/9_1_3_20170104222949455.jpg.chip.jpg    9       1          3   \n",
       "23702    UTKFace/9_1_4_20170103200637399.jpg.chip.jpg    9       1          4   \n",
       "23703    UTKFace/9_1_4_20170103200814791.jpg.chip.jpg    9       1          4   \n",
       "23704    UTKFace/9_1_4_20170103213057382.jpg.chip.jpg    9       1          4   \n",
       "\n",
       "       Age_Class Age_Bin  \n",
       "0             10     80+  \n",
       "1             10     80+  \n",
       "2             10     80+  \n",
       "3             10     80+  \n",
       "4             10     80+  \n",
       "...          ...     ...  \n",
       "23700          0     0-9  \n",
       "23701          0     0-9  \n",
       "23702          0     0-9  \n",
       "23703          0     0-9  \n",
       "23704          0     0-9  \n",
       "\n",
       "[23705 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the bin edges\n",
    "bins = list(range(0, 81, 10)) + [df['Age'].max() + 1]  # This adds a final upper bound for 80+\n",
    "\n",
    "# Create bin labels (optional)\n",
    "labels = [f\"{i}-{i+9}\" for i in range(0, 80, 10)] + ['80+']\n",
    "\n",
    "# Apply binning\n",
    "df['Age_Bin'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba67155",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train-test split, used for evaluating final model\u001b[39;00m\n\u001b[32m      3\u001b[39m df_train, df_test = train_test_split(df, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train_cv, y_train_cv = \u001b[43mdf_to_np_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m X_test, y_test = df_to_np_arrays(df_test, IMG_DIM)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maduj\\OneDrive\\Documenten\\GitHub\\TXAI2425\\utils.py:70\u001b[39m, in \u001b[36mdf_to_np_arrays\u001b[39m\u001b[34m(df, img_dim)\u001b[39m\n\u001b[32m     68\u001b[39m age_class = row[\u001b[33m'\u001b[39m\u001b[33mAge_Class\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     img = \u001b[43mload_image_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     images.append(img)\n\u001b[32m     72\u001b[39m     labels.append(age_class)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maduj\\OneDrive\\Documenten\\GitHub\\TXAI2425\\utils.py:53\u001b[39m, in \u001b[36mload_image_np\u001b[39m\u001b[34m(filepath, img_dim)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_image_np\u001b[39m(filepath, img_dim=\u001b[32m200\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     image = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     image = tf.io.decode_jpeg(image, channels=\u001b[32m3\u001b[39m)\n\u001b[32m     55\u001b[39m     image = tf.image.resize(image, [img_dim, img_dim])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maduj\\anaconda3\\envs\\texai\\Lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:134\u001b[39m, in \u001b[36mread_file\u001b[39m\u001b[34m(filename, name)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mio.read_file\u001b[39m\u001b[33m\"\u001b[39m, v1=[\u001b[33m\"\u001b[39m\u001b[33mio.read_file\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mread_file\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_file\u001b[39m(filename, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     99\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m \u001b[33;03m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_io_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maduj\\anaconda3\\envs\\texai\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:583\u001b[39m, in \u001b[36mread_file\u001b[39m\u001b[34m(filename, name)\u001b[39m\n\u001b[32m    581\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_file_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._SymbolicException:\n\u001b[32m    586\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maduj\\anaconda3\\envs\\texai\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:606\u001b[39m, in \u001b[36mread_file_eager_fallback\u001b[39m\u001b[34m(filename, name, ctx)\u001b[39m\n\u001b[32m    604\u001b[39m _inputs_flat = [filename]\n\u001b[32m    605\u001b[39m _attrs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m _result = \u001b[43m_execute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReadFile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n\u001b[32m    609\u001b[39m   _execute.record_gradient(\n\u001b[32m    610\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mReadFile\u001b[39m\u001b[33m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maduj\\anaconda3\\envs\\texai\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train-test split, used for evaluating final model\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_train_cv, y_train_cv = df_to_np_arrays(df_train, IMG_DIM)\n",
    "X_test, y_test = df_to_np_arrays(df_test, IMG_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0e589",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train-val split, used for evaluating intermediate model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_train_tune, df_val_tune \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(df_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m X_train_tune, y_train_tune \u001b[38;5;241m=\u001b[39m df_to_np_arrays(df_train_tune)\n\u001b[1;32m      5\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m df_to_np_arrays(df_val_tune)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Train-val split, used for evaluating intermediate model\n",
    "\n",
    "df_train_tune, df_val_tune = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "X_train_tune, y_train_tune = df_to_np_arrays(df_train_tune)\n",
    "X_val, y_val = df_to_np_arrays(df_val_tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa34dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-val split, used for evaluating intermediate model\n",
    "\n",
    "df_train_tune, df_val_tune = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "max_count = df_train_tune['Age_Bin'].value_counts().max()\n",
    "\n",
    "df_balanced_age = df_train_tune.groupby('Age_Bin').apply(\n",
    "    lambda x: x.sample(max_count, replace=True, random_state=1)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "max_count = df_balanced_age['Ethnicity'].value_counts().max()\n",
    "\n",
    "df_balanced_age_race = df_balanced_age.groupby('Ethnicity').apply(\n",
    "    lambda x: x.sample(max_count, replace=True, random_state=1)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train_tune, y_train_tune = df_to_np_arrays(df_balanced_age_race)\n",
    "X_val, y_val = df_to_np_arrays(df_val_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c69318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on existing research found here: https://www.kaggle.com/datasets/jangedoo/utkface-new/code\n",
    "\n",
    "class AgeHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        inputs = Input(shape=INPUT_SHAPE, dtype=tf.float32, name=\"input_image\")\n",
    "        \n",
    "        hp_use_batch_norm = hp.Boolean(\"use_batch_norm_global\", default=False)\n",
    "        hp_dropout_rate = hp.Float(\"dropout_rate_global\", min_value=0.1, max_value=0.5, step=0.1, default=0.25)\n",
    "        hp_num_conv_blocks = hp.Int(\"num_conv_blocks\", min_value=1, max_value=4, step=1, default=3)\n",
    "        \n",
    "        current_filters = 0  # Tracks filters in the latest conv layer.\n",
    "        x = inputs\n",
    "\n",
    "        for i in range(hp_num_conv_blocks):\n",
    "            if i == 0:\n",
    "                # First conv block: choice between 32 and 64 filters.\n",
    "                current_filters = hp.Choice(\"filters_start\", values=[32, 64], default=32)\n",
    "            else:\n",
    "                # Next blocks: double filters (capped at 512).\n",
    "                current_filters = min(512, current_filters * 2)\n",
    "\n",
    "            x = layers.Conv2D(filters=current_filters, kernel_size=FIXED_KERNEL_SIZE, activation=None)(x)\n",
    "\n",
    "            if hp_use_batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        \n",
    "        last_conv_filters = current_filters\n",
    "        x = layers.Flatten(name=\"flatten\")(x)\n",
    "\n",
    "        hp_num_dense_layers = hp.Int(\"num_dense_layers\", min_value=1, max_value=3, step=1, default=2)\n",
    "        current_dense_units = 0\n",
    "\n",
    "        for i in range(hp_num_dense_layers):\n",
    "            hp_size_choice = hp.Choice(\"size_choice\", values=[\"same\", \"half\"], default=\"half\")\n",
    "\n",
    "            if hp_size_choice == \"same\":\n",
    "                current_dense_units = max(MIN_DENSE_UNITS, last_conv_filters)\n",
    "            else:\n",
    "                current_dense_units = max(MIN_DENSE_UNITS, last_conv_filters // 2)\n",
    "\n",
    "            x = layers.Dense(units=current_dense_units, activation=\"relu\")(x)\n",
    "            x = layers.Dropout(rate=hp_dropout_rate)(x)\n",
    "        \n",
    "        outputs = layers.Dense(NUM_AGE_CLASSES, activation=\"softmax\", name=\"age_class_output\")(x)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        hp_learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\", default=1e-3)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Idea taken from: https://github.com/keras-team/keras-tuner/issues/122#issuecomment-544648268\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(*args, batch_size=hp.Choice(\"batch_size\", values=[32, 64, 128, 256], default=64), **kwargs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c2683ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparameter_tuning/ageclass_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    AgeHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    factor=3,\n",
    "    directory=\"hyperparameter_tuning\",\n",
    "    project_name=\"ageclass_tuning\",\n",
    "    # max_trials=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81789cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    train_dataset_tune,\n",
    "    validation_data=val_dataset_tune,\n",
    "    epochs=20,\n",
    "    callbacks=[callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
