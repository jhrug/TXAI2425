{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cfc1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 23:04:42.574916: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 23:04:42.762524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744059882.827932   96408 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744059882.847181   96408 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744059882.997988   96408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744059882.998004   96408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744059882.998006   96408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744059882.998007   96408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-07 23:04:43.015962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import Input, Model, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import prepare_dataframe, df_to_np_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0e1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1f4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4f6a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"datasets/utkface/\"\n",
    "IMG_DIM = 200\n",
    "INPUT_SHAPE = (IMG_DIM, IMG_DIM, 3)\n",
    "\n",
    "FIXED_KERNEL_SIZE = (3, 3)\n",
    "MIN_DENSE_UNITS = 16\n",
    "NUM_AGE_CLASSES = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdae1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f77fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define the bin edges\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m bins = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m81\u001b[39m, \u001b[32m10\u001b[39m)) + [\u001b[43mdf_train_tune\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m].max() + \u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# This adds a final upper bound for 80+\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create bin labels (optional)\u001b[39;00m\n\u001b[32m      5\u001b[39m labels = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m9\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m80\u001b[39m, \u001b[32m10\u001b[39m)] + [\u001b[33m'\u001b[39m\u001b[33m80+\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df_train_tune' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the bin edges\n",
    "bins = list(range(0, 81, 10)) + [df_train_tune['Age'].max() + 1]  # This adds a final upper bound for 80+\n",
    "\n",
    "# Create bin labels (optional)\n",
    "labels = [f\"{i}-{i+9}\" for i in range(0, 80, 10)] + ['80+']\n",
    "\n",
    "# Apply binning\n",
    "df['Age_Bin'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba67155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split, used for evaluating final model\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_train_cv, y_train_cv = df_to_np_arrays(df_train, IMG_DIM)\n",
    "X_test, y_test = df_to_np_arrays(df_test, IMG_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df0e589",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train-val split, used for evaluating intermediate model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_train_tune, df_val_tune \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(df_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m X_train_tune, y_train_tune \u001b[38;5;241m=\u001b[39m df_to_np_arrays(df_train_tune)\n\u001b[1;32m      5\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m df_to_np_arrays(df_val_tune)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Train-val split, used for evaluating intermediate model\n",
    "\n",
    "df_train_tune, df_val_tune = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "X_train_tune, y_train_tune = df_to_np_arrays(df_train_tune)\n",
    "X_val, y_val = df_to_np_arrays(df_val_tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa34dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_count = df['Age_Bin'].value_counts().max()\n",
    "\n",
    "df_balanced_age = df.groupby('Age_Bin').apply(\n",
    "    lambda x: x.sample(max_count, replace=True, random_state=1)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "max_count = df_balanced_age['Ethnicity'].value_counts().max()\n",
    "\n",
    "df_balanced_age_race = df_balanced_age.groupby('Ethnicity').apply(\n",
    "    lambda x: x.sample(max_count, replace=True, random_state=1)\n",
    "    ).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c69318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on existing research found here: https://www.kaggle.com/datasets/jangedoo/utkface-new/code\n",
    "\n",
    "class AgeHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        inputs = Input(shape=INPUT_SHAPE, dtype=tf.float32, name=\"input_image\")\n",
    "        \n",
    "        hp_use_batch_norm = hp.Boolean(\"use_batch_norm_global\", default=False)\n",
    "        hp_dropout_rate = hp.Float(\"dropout_rate_global\", min_value=0.1, max_value=0.5, step=0.1, default=0.25)\n",
    "        hp_num_conv_blocks = hp.Int(\"num_conv_blocks\", min_value=1, max_value=4, step=1, default=3)\n",
    "        \n",
    "        current_filters = 0  # Tracks filters in the latest conv layer.\n",
    "        x = inputs\n",
    "\n",
    "        for i in range(hp_num_conv_blocks):\n",
    "            if i == 0:\n",
    "                # First conv block: choice between 32 and 64 filters.\n",
    "                current_filters = hp.Choice(\"filters_start\", values=[32, 64], default=32)\n",
    "            else:\n",
    "                # Next blocks: double filters (capped at 512).\n",
    "                current_filters = min(512, current_filters * 2)\n",
    "\n",
    "            x = layers.Conv2D(filters=current_filters, kernel_size=FIXED_KERNEL_SIZE, activation=None)(x)\n",
    "\n",
    "            if hp_use_batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        \n",
    "        last_conv_filters = current_filters\n",
    "        x = layers.Flatten(name=\"flatten\")(x)\n",
    "\n",
    "        hp_num_dense_layers = hp.Int(\"num_dense_layers\", min_value=1, max_value=3, step=1, default=2)\n",
    "        current_dense_units = 0\n",
    "\n",
    "        for i in range(hp_num_dense_layers):\n",
    "            hp_size_choice = hp.Choice(\"size_choice\", values=[\"same\", \"half\"], default=\"half\")\n",
    "\n",
    "            if hp_size_choice == \"same\":\n",
    "                current_dense_units = max(MIN_DENSE_UNITS, last_conv_filters)\n",
    "            else:\n",
    "                current_dense_units = max(MIN_DENSE_UNITS, last_conv_filters // 2)\n",
    "\n",
    "            x = layers.Dense(units=current_dense_units, activation=\"relu\")(x)\n",
    "            x = layers.Dropout(rate=hp_dropout_rate)(x)\n",
    "        \n",
    "        outputs = layers.Dense(NUM_AGE_CLASSES, activation=\"softmax\", name=\"age_class_output\")(x)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        hp_learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\", default=1e-3)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Idea taken from: https://github.com/keras-team/keras-tuner/issues/122#issuecomment-544648268\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(*args, batch_size=hp.Choice(\"batch_size\", values=[32, 64, 128, 256], default=64), **kwargs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c2683ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparameter_tuning/ageclass_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    AgeHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    factor=3,\n",
    "    directory=\"hyperparameter_tuning\",\n",
    "    project_name=\"ageclass_tuning\",\n",
    "    # max_trials=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81789cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    train_dataset_tune,\n",
    "    validation_data=val_dataset_tune,\n",
    "    epochs=20,\n",
    "    callbacks=[callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
